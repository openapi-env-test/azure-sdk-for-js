/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

import * as msRest from "@azure/ms-rest-js";
import * as Models from "./models";
import * as Mappers from "./models/mappers";
import * as Parameters from "./models/parameters";
import * as operations from "./operations";
import { FaceClientContext } from "./faceClientContext";

class FaceClient extends FaceClientContext {
  // Operation groups
  face: operations.Face;
  personGroupPerson: operations.PersonGroupPerson;
  personGroup: operations.PersonGroupOperations;
  faceList: operations.FaceListOperations;
  largePersonGroupPerson: operations.LargePersonGroupPerson;
  largePersonGroup: operations.LargePersonGroupOperations;
  largeFaceList: operations.LargeFaceListOperations;
  snapshot: operations.SnapshotOperations;

  /**
   * Initializes a new instance of the FaceClient class.
   * @param endpoint Supported Cognitive Services endpoints (protocol and hostname, for example:
   * https://westus.api.cognitive.microsoft.com).
   * @param credentials Subscription credentials which uniquely identify client subscription.
   * @param [options] The parameter options
   */
  constructor(credentials: msRest.ServiceClientCredentials, endpoint: string, options?: msRest.ServiceClientOptions) {
    super(credentials, endpoint, options);
    this.face = new operations.Face(this);
    this.personGroupPerson = new operations.PersonGroupPerson(this);
    this.personGroup = new operations.PersonGroupOperations(this);
    this.faceList = new operations.FaceListOperations(this);
    this.largePersonGroupPerson = new operations.LargePersonGroupPerson(this);
    this.largePersonGroup = new operations.LargePersonGroupOperations(this);
    this.largeFaceList = new operations.LargeFaceListOperations(this);
    this.snapshot = new operations.SnapshotOperations(this);
  }

  /**
   * @summary Detects liveness of a target face in a sequence of images of the same stream type (e.g.
   * color)
   * @param content A ordered collection of application/octet-stream data containing the input data.
   * @param metadataImageType Describes the image type based on the camera modality. Possible values
   * include: 'color', 'infrared', 'depth'
   * @param metadataImageData An array of image metadata corresponding to each image in the input
   * content payload.
   * @param [options] The optional parameters
   * @returns Promise<Models.DetectLivenessSingleModalPostResponse>
   */
  detectLivenessSingleModalPost(content: any[], metadataImageType: Models.MetadataImageType, metadataImageData: any[], options?: Models.FaceClientDetectLivenessSingleModalPostOptionalParams): Promise<Models.DetectLivenessSingleModalPostResponse>;
  /**
   * @param content A ordered collection of application/octet-stream data containing the input data.
   * @param metadataImageType Describes the image type based on the camera modality. Possible values
   * include: 'color', 'infrared', 'depth'
   * @param metadataImageData An array of image metadata corresponding to each image in the input
   * content payload.
   * @param callback The callback
   */
  detectLivenessSingleModalPost(content: any[], metadataImageType: Models.MetadataImageType, metadataImageData: any[], callback: msRest.ServiceCallback<Models.LivenessOutputs>): void;
  /**
   * @param content A ordered collection of application/octet-stream data containing the input data.
   * @param metadataImageType Describes the image type based on the camera modality. Possible values
   * include: 'color', 'infrared', 'depth'
   * @param metadataImageData An array of image metadata corresponding to each image in the input
   * content payload.
   * @param options The optional parameters
   * @param callback The callback
   */
  detectLivenessSingleModalPost(content: any[], metadataImageType: Models.MetadataImageType, metadataImageData: any[], options: Models.FaceClientDetectLivenessSingleModalPostOptionalParams, callback: msRest.ServiceCallback<Models.LivenessOutputs>): void;
  detectLivenessSingleModalPost(content: any[], metadataImageType: Models.MetadataImageType, metadataImageData: any[], options?: Models.FaceClientDetectLivenessSingleModalPostOptionalParams | msRest.ServiceCallback<Models.LivenessOutputs>, callback?: msRest.ServiceCallback<Models.LivenessOutputs>): Promise<Models.DetectLivenessSingleModalPostResponse> {
    return this.sendOperationRequest(
      {
        content,
        metadataImageType,
        metadataImageData,
        options
      },
      detectLivenessSingleModalPostOperationSpec,
      callback) as Promise<Models.DetectLivenessSingleModalPostResponse>;
  }

  /**
   * @summary Detects liveness of a target face in a sequence of infrared, color and/or depth images.
   * @param content A ordered collection of application/octet-stream data containing the input data.
   * @param metadataImageData An array of image metadata corresponding to each image in the input
   * content payload.
   * @param metadataModalitiesSupportedByCamera An array of modalities supported by camera, e.g. {
   * color, infrared } or { color, infrared, depth }
   * @param [options] The optional parameters
   * @returns Promise<Models.DetectLivenessMultiModalPostResponse>
   */
  detectLivenessMultiModalPost(content: any[], metadataImageData: any[], metadataModalitiesSupportedByCamera: string[], options?: Models.FaceClientDetectLivenessMultiModalPostOptionalParams): Promise<Models.DetectLivenessMultiModalPostResponse>;
  /**
   * @param content A ordered collection of application/octet-stream data containing the input data.
   * @param metadataImageData An array of image metadata corresponding to each image in the input
   * content payload.
   * @param metadataModalitiesSupportedByCamera An array of modalities supported by camera, e.g. {
   * color, infrared } or { color, infrared, depth }
   * @param callback The callback
   */
  detectLivenessMultiModalPost(content: any[], metadataImageData: any[], metadataModalitiesSupportedByCamera: string[], callback: msRest.ServiceCallback<Models.LivenessOutputs>): void;
  /**
   * @param content A ordered collection of application/octet-stream data containing the input data.
   * @param metadataImageData An array of image metadata corresponding to each image in the input
   * content payload.
   * @param metadataModalitiesSupportedByCamera An array of modalities supported by camera, e.g. {
   * color, infrared } or { color, infrared, depth }
   * @param options The optional parameters
   * @param callback The callback
   */
  detectLivenessMultiModalPost(content: any[], metadataImageData: any[], metadataModalitiesSupportedByCamera: string[], options: Models.FaceClientDetectLivenessMultiModalPostOptionalParams, callback: msRest.ServiceCallback<Models.LivenessOutputs>): void;
  detectLivenessMultiModalPost(content: any[], metadataImageData: any[], metadataModalitiesSupportedByCamera: string[], options?: Models.FaceClientDetectLivenessMultiModalPostOptionalParams | msRest.ServiceCallback<Models.LivenessOutputs>, callback?: msRest.ServiceCallback<Models.LivenessOutputs>): Promise<Models.DetectLivenessMultiModalPostResponse> {
    return this.sendOperationRequest(
      {
        content,
        metadataImageData,
        metadataModalitiesSupportedByCamera,
        options
      },
      detectLivenessMultiModalPostOperationSpec,
      callback) as Promise<Models.DetectLivenessMultiModalPostResponse>;
  }
}

// Operation Specifications
const serializer = new msRest.Serializer(Mappers);
const detectLivenessSingleModalPostOperationSpec: msRest.OperationSpec = {
  httpMethod: "POST",
  path: "detectLiveness/singleModal",
  urlParameters: [
    Parameters.endpoint
  ],
  queryParameters: [
    Parameters.content,
    Parameters.modelVersion
  ],
  formDataParameters: [
    Parameters.metadataImageType,
    Parameters.metadataImageData
  ],
  contentType: "multipart/form-data",
  responses: {
    200: {
      bodyMapper: Mappers.LivenessOutputs
    },
    400: {},
    401: {},
    403: {},
    408: {},
    415: {},
    429: {},
    default: {
      bodyMapper: Mappers.ErrorResponse
    }
  },
  serializer
};

const detectLivenessMultiModalPostOperationSpec: msRest.OperationSpec = {
  httpMethod: "POST",
  path: "detectLiveness/multiModal",
  urlParameters: [
    Parameters.endpoint
  ],
  queryParameters: [
    Parameters.content,
    Parameters.modelVersion
  ],
  formDataParameters: [
    Parameters.metadataImageData,
    Parameters.metadataModalitiesSupportedByCamera,
    Parameters.metadataCameraCalibrationParameters
  ],
  contentType: "multipart/form-data",
  responses: {
    200: {
      bodyMapper: Mappers.LivenessOutputs
    },
    400: {},
    401: {},
    403: {},
    408: {},
    415: {},
    429: {},
    default: {
      bodyMapper: Mappers.ErrorResponse
    }
  },
  serializer
};

export {
  FaceClient,
  FaceClientContext,
  Models as FaceModels,
  Mappers as FaceMappers
};
export * from "./operations";
